---
benchmark:
  name: "Driving SMARTS 2023.1"
  message: |
    For context see: 
        - https://smarts-project.github.io/competition/2023_driving_smarts/
        - https://codalab.lisn.upsaclay.fr/competitions/
  eval_episodes: 50
  debug:
    serial: True
  shared_env_kwargs:
    seed: 42
    headless: True
  envs:
    standard:
      loc: "smarts.env:driving-smarts-v2023"
      scenarios:
        - scenarios/sumo/straight/cruise_2lane_agents_1
        - scenarios/sumo/straight/cutin_2lane_agents_1
        - scenarios/sumo/straight/merge_exit_sumo_t_agents_1
        - scenarios/sumo/straight/overtake_2lane_agents_1
      kwargs:
        seed: 42
      metric_formula: smarts/benchmark/driving_smarts/v2023/metric_formula_drive.py