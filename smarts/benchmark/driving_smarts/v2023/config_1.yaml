---
benchmark:
  name: "Driving SMARTS 2023.1"
  message: |
    For context see: 
        - https://smarts-project.github.io/competition/2023_driving_smarts/
        - https://codalab.lisn.upsaclay.fr/competitions/
  eval_episodes: 50
  debug:
    serial: True
  shared_env_kwargs:
    seed: 42
    headless: True
  envs:
    standard:
      loc: "smarts.env:driving-smarts-v2023"
      scenarios:
        - scenarios/sumo/straight/cruise_2lane_agents_1
        - scenarios/sumo/straight/cutin_2lane_agents_1
        - scenarios/sumo/straight/merge_exit_sumo_t_agents_1
        - scenarios/sumo/straight/overtake_2lane_agents_1

        # - driving-smarts-2.competition-scenarios/t1/training/00a445fb-7293-4be6-adbc-e30c949b6cf7_agents_1
        # - driving-smarts-2.competition-scenarios/t1/training/0a53dd99-2946-4b4d-ab66-c4d6fef97be2_agents_1
        # - driving-smarts-2.competition-scenarios/t1/training/0a576bf1-66ae-495a-9c87-236f3fc2aa01_agents_1

      kwargs:
        seed: 42
      metric_formula: smarts/benchmark/driving_smarts/v2023/metric_formula_drive.py