smarts:
  # Environment
  sumo_gui: False # If True, enables sumo-gui display.
  seed: 42
  agent_locator: inference:contrib-agent-v0
  env_id: smarts.env:driving-smarts-v2023  
  scenarios:
    - scenarios/sumo/straight/cruise_2lane_agents_1
    - scenarios/sumo/straight/cutin_2lane_agents_1
    - scenarios/sumo/straight/merge_exit_sumo_t_agents_1
    - scenarios/sumo/straight/overtake_2lane_agents_1

    # - driving-smarts-2.competition-scenarios/t1/training/00a445fb-7293-4be6-adbc-e30c949b6cf7_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/0a53dd99-2946-4b4d-ab66-c4d6fef97be2_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/0a576bf1-66ae-495a-9c87-236f3fc2aa01_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/cruise_2lane_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/cutin_2lane_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/merge_exit_sumo_t_agents_1
    # - driving-smarts-2.competition-scenarios/t1/training/overtake_2lane_agents_1

    - scenarios/sumo/intersections/1_to_3lane_left_turn_sumo_c_agents_1
    - scenarios/sumo/intersections/1_to_3lane_left_turn_middle_lane_c_agents_1

    # - driving-smarts-2.competition-scenarios/t2/training/0a60b442-56b0-46c3-be45-cf166a182b67_agents_1
    # - driving-smarts-2.competition-scenarios/t2/training/0a764a82-b44e-481e-97e7-05e1f1f925f6_agents_1
    # - driving-smarts-2.competition-scenarios/t2/training/00b15e74-04a8-4bd4-9a78-eb24f0c0a980_agents_1
    # - driving-smarts-2.competition-scenarios/t2/training/0bf054e3-7698-4b86-9c98-626df2dee9f4_agents_1
    # - driving-smarts-2.competition-scenarios/t2/training/1_to_3lane_left_turn_middle_lane_c_agents_1
    # - driving-smarts-2.competition-scenarios/t2/training/1_to_3lane_left_turn_sumo_c_agents_1

  # PPO algorithm
  alg:
    n_steps: 2048
    batch_size: 64
    n_epochs: 5
    target_kl: 0.1
    ent_coef: 0.01 # For exploration. Range = 0 to 0.01

  # Training over all scenarios
  epochs: 500 # Number of training loops.

  # Training per scenario
  train_steps: 8_192
  checkpoint_freq: 8_192 # Save a model every checkpoint_freq calls to env.step().
  eval_freq: 8_192 # Evaluate the trained model every eval_freq steps and save the best model.
  eval_eps: 5 # Number of evaluation epsiodes.
