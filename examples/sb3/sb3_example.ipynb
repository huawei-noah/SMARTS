{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gsMrWT3u4WM"
      },
      "source": [
        "Install SUMO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou2m2vdkt6gt"
      },
      "outputs": [],
      "source": [
        "# Setup SUMO=1.10.0\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install -y libspatialindex-dev\n",
        "%pip install --upgrade pip wheel\n",
        "%pip install eclipse-sumo==1.10.0\n",
        "%env SUMO_HOME=/usr/local/lib/python3.7/dist-packages/sumo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovtp6ZCSuz1a"
      },
      "source": [
        "Install SMARTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O_JXIJ0t8ub"
      },
      "outputs": [],
      "source": [
        "# Install SMARTS\n",
        "%cd ~\n",
        "!rm -rf /content/SMARTS\n",
        "!git clone https://github.com/huawei-noah/SMARTS /content/SMARTS\n",
        "!cd /content/SMARTS && git checkout 'develop' && git pull && pip install .[camera-obs]\n",
        "!echo -e \"import sys\\nsys.path.insert(0, '/content/SMARTS/')\" | python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrqfhFxtvmN5"
      },
      "source": [
        "Install Stable Baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3NGSm58vldU"
      },
      "outputs": [],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGJgn7UZu76M"
      },
      "source": [
        "Build the scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2xr24JSuWd3"
      },
      "outputs": [],
      "source": [
        "# Build scenarios\n",
        "!scl scenario build-all --clean /content/SMARTS/scenarios/loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx__xXLNpC25"
      },
      "source": [
        "Restart the runtime to change dependency versions. (Ctrl+M .) Continue from here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDGS3RHwfOT8"
      },
      "outputs": [],
      "source": [
        "%env SUMO_HOME=/usr/local/lib/python3.7/dist-packages/sumo\n",
        "%cd /content/SMARTS/examples/sb3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v0xcpPfv6L3"
      },
      "source": [
        "Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWsQgj0NvGNt"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "from smarts.core import agent as smarts_agent\n",
        "from smarts.core import agent_interface as smarts_agent_interface\n",
        "from smarts.core import controllers as smarts_controllers\n",
        "from smarts.env import hiway_env as smarts_hiway_env\n",
        "import smarts.env.wrappers.rgb_image as smarts_rgb_image\n",
        "import smarts.env.wrappers.single_agent as smarts_single_agent\n",
        "import sb3.env.reward as reward\n",
        "import sb3.env.action as action\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common import monitor\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "def main(scenarios, headless, seed, sim_name):\n",
        "\n",
        "    vehicle_interface = smarts_agent_interface.AgentInterface(\n",
        "        max_episode_steps=300,\n",
        "        rgb=smarts_agent_interface.RGB(\n",
        "            width=64,\n",
        "            height=64,\n",
        "            resolution=1,\n",
        "        ),\n",
        "        action=getattr(\n",
        "            smarts_controllers.ActionSpaceType,\n",
        "            \"Continuous\",\n",
        "        ),\n",
        "        done_criteria=smarts_agent_interface.DoneCriteria(\n",
        "            collision=True,\n",
        "            off_road=True,\n",
        "            off_route=False,\n",
        "            on_shoulder=False,\n",
        "            wrong_way=False,\n",
        "            not_moving=False,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    agent_specs = {\n",
        "        \"Agent-007\": smarts_agent.AgentSpec(\n",
        "            interface=vehicle_interface,\n",
        "            agent_builder=None,\n",
        "        )\n",
        "    }\n",
        "\n",
        "    env = smarts_hiway_env.HiWayEnv(\n",
        "        scenarios=scenarios,\n",
        "        agent_specs=agent_specs,\n",
        "        headless=headless,\n",
        "        visdom=False,\n",
        "        seed=seed,\n",
        "        sim_name=sim_name,\n",
        "    )\n",
        "\n",
        "    # Wrap env with ActionWrapper\n",
        "    env = action.Action(env=env)\n",
        "    # Wrap env with RewardWrapper\n",
        "    env = reward.Reward(env=env)\n",
        "    # Wrap env with RGBImage wrapper to only get rgb images in observation\n",
        "    env = smarts_rgb_image.RGBImage(env=env, num_stack=1)\n",
        "    # Wrap env with SingleAgent wrapper to be Gym compliant\n",
        "    env = smarts_single_agent.SingleAgent(env=env)\n",
        "    env = monitor.Monitor(env=env)\n",
        "    check_env(env, warn=True)\n",
        "\n",
        "    # create the model\n",
        "    model = PPO(\"CnnPolicy\", env, verbose=1, n_steps=50, batch_size=50)\n",
        "\n",
        "    # evaluate at the beginning\n",
        "    before_mean_reward, before_std_reward = evaluate_policy(\n",
        "        model, env, n_eval_episodes=10, deterministic=True\n",
        "    )\n",
        "    model.learn(total_timesteps=500000)\n",
        "\n",
        "    # evaluate after training\n",
        "    mean_reward, std_reward = evaluate_policy(\n",
        "        model, env, n_eval_episodes=10, deterministic=True\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"before_mean_reward:{before_mean_reward:.2f} +/- {before_std_reward:.2f}\"\n",
        "    )\n",
        "    print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3JVKDRdyANx"
      },
      "source": [
        "Run the example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0MXABlGxiIC"
      },
      "outputs": [],
      "source": [
        "# allow offscreen render\n",
        "import os\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "\n",
        "main(\n",
        "    scenarios=[\"/content/SMARTS/scenarios/loop\"],\n",
        "    sim_name=\"SB3-PPO\",\n",
        "    headless=True,\n",
        "    seed=42,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sb3_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
