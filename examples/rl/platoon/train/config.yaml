smarts:
  # Environment
  sumo_gui: False # If True, enables sumo-gui display.
  seed: 42
  agent_locator: inference:contrib-agent-v0
  env_id: smarts.env:platoon-v0
  scenarios:
    - scenarios/sumo/vehicle_following/straight_2lane_sumo_agents_1
    - scenarios/sumo/vehicle_following/straight_2lane_sumo_t_agents_1
    - scenarios/sumo/vehicle_following/straight_3lanes_sumo_agents_1
    - scenarios/sumo/vehicle_following/straight_3lanes_sumo_t_agents_1
    - scenarios/sumo/vehicle_following/merge_exit_sumo_agents_1
    - scenarios/sumo/vehicle_following/merge_exit_sumo_t_agents_1

  # PPO algorithm
  alg:
    n_steps: 1024
    batch_size: 64
    n_epochs: 4
    target_kl: 0.1
    # ent_coef: 0.01 # For exploration. Range = 0 to 0.01

  # Training over all scenarios
  epochs: 500 # Number of training loops.

  # Training per scenario
  train_steps: 4_096
  checkpoint_freq: 4_096 # Save a model every checkpoint_freq calls to env.step().
  eval_freq: 4_096 # Evaluate the trained model every eval_freq steps and save the best model.
  eval_eps: 5 # Number of evaluation epsiodes.
